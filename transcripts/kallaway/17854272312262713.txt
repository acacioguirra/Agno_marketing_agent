 Apple's doing something for the first time with the iPhone 16. Visual intelligence. It's pretty sick. Let's say you're walking around and you see somebody wearing a cool shirt. All you have to do is point your camera at the shirt and Apple will use their AI layer to find out the brand and give you the link. Now imagine that across every use case. Your car engine light is on. You point the camera and Apple tells you how to figure it out. All of a sudden, your phone becomes this super smart visual assistant. Eventually, it might be able to look at a poster on the street and redesign yours or analyze an injury and help diagnose what to do. All visually, just by pointing your iPhone camera. And to me, this was the big takeaway of the event. All of the coolest stuff was about making the camera smarter and easier to use. This new camera button, crazy video features, cool photo recipes. I was kind of wondering what Apple is going to do to keep people upgrading. But it's the visual AI that's going to make these phones so much more powerful than every other model. And their strategy, of course, is super smart. Make the AI layer free, but make it so powerful that only the latest phones are advanced enough to run it. It's super clear that the future of mobile computing is gonna be visually based. Show the computer something and let it react. And that's either gonna come from smart glasses you wear or a camera you hold. So it looks to me like Apple just made their first AI chess move.